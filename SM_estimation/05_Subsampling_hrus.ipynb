{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependancies\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths and size\n",
    "# Load results from clustering\n",
    "\n",
    "clustering_feature_names = ['MON',  'PRECIP' , 'AREA', 'DAILYCN', 'SNOMELT' ,'SNOFALL', 'SURQ_GEN', 'LATQ', 'WYLD', 'PET']\n",
    "data_path = '/Users/muneeza/Documents/GitHub/DATA_SMest/HRU_Clustering_results/'\n",
    "\n",
    "# all_data = np.load(data_path+'hru_clustering_data.npy')\n",
    "X_train_norm = np.load(data_path+'norm_hru_clustering_data.npy')\n",
    "dist = np.load(data_path+'hru_cluster_distance.npy')\n",
    "centroid = np.load(data_path+'cluster_centers.npy')\n",
    "labels = np.load(data_path+'hru_cluster_labels.npy')\n",
    "with open(data_path+'names_list_clustering.pkl', 'rb') as f:\n",
    "    names_list = pickle.load(f)\n",
    "\n",
    "n_hrus = np.array([x.split('.')[-2] for x in names_list]).astype(int)\n",
    "hrus_total = np.sum(n_hrus)\n",
    "\n",
    "mean_t = np.mean(X_train_norm,0)\n",
    "var_t = np.var(X_train_norm,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new names list with hru ids \n",
    "hru_names_list = []\n",
    "for i, name in enumerate(names_list):\n",
    "    for j in range(n_hrus[i]):\n",
    "        hru_names_list.append(name.split('_')[0]+'.'+str(n_hrus[i])+'.'+str(j))\n",
    "\n",
    "pickle.dump(names_list, open(data_path+'hru_names_list_clustering.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Visualize all clustered Data \n",
    "\n",
    "# color = []\n",
    "# n = 12 # number of clusters\n",
    "# for i in range(n):\n",
    "#     color.append('#%06X' % randint(0, 0xFFFFFF))\n",
    "\n",
    "# # Generate Subplot\n",
    "# fig, ax = plt.subplots(3,3,figsize=(10,10))\n",
    "# for i in range(3):\n",
    "#     for j in range(3):\n",
    "#         if i*3+j+1> 9 : # pass the others that we can't fill\n",
    "#             continue\n",
    "#         for k in range(n_sample):\n",
    "#             ax[i, j].plot(np.transpose(X_train_norm[k,:,i*3+j+1]), color=color[labels[k]], linewidth=0.5)\n",
    "#             ax[i, j].set_title(clustering_feature_names[i*3+j+1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min err in inertia: 3566.1470389062515\n",
      "min err in inertia: 1772.6207281498946\n",
      "min err in inertia: 1620.699867847421\n",
      "min err in inertia: 3515.9254997760318\n",
      "min err in inertia: 2215.908829697929\n",
      "min err in inertia: 4056.403579246665\n",
      "min err in inertia: 879.7470199048904\n",
      "min err in inertia: 1723.9483434157498\n",
      "min err in inertia: 4331.763716158501\n",
      "min err in inertia: 109.40829916388688\n",
      "min err in inertia: 4111.834532797489\n",
      "min err in inertia: 3791.311107249996\n"
     ]
    }
   ],
   "source": [
    "# Sample a subset of data that is 'close enough' to original data - error in inertia < t \n",
    "\n",
    "n_cluster = 12\n",
    "inertia = np.zeros(n_cluster)\n",
    "inertia_sub = np.zeros(n_cluster)\n",
    "names_list_cluster = [None]*n_cluster\n",
    "names_list_sub_cluster = [None]*n_cluster\n",
    "\n",
    "for i in range(n_cluster):\n",
    "    \n",
    "    id_cluster = np.argwhere(labels == i)[:,0] \n",
    "    inertia[i] = np.sum(dist[id_cluster,i])\n",
    "    names_list_cluster[i] = [hru_names_list[x] for x in id_cluster]\n",
    "\n",
    "    hrus_in_cluster = len(id_cluster)\n",
    "    hrus_in_sub_cluster = int(hrus_in_cluster*0.2)  # 10% of original data \n",
    "\n",
    "    err_min = 200000\n",
    "\n",
    "    for j in range (100000):\n",
    "        sample = np.random.uniform(0,hrus_in_cluster,hrus_in_sub_cluster).astype(int)\n",
    "        sample_id = id_cluster[sample]\n",
    "        sample_inertia = np.sum(dist[sample_id,i])\n",
    "        err_new = np.abs(inertia[i]-sample_inertia)\n",
    "        if err_new < err_min:\n",
    "            err_min = err_new\n",
    "            id_min_cluster = sample_id\n",
    "            inertia_sub[i] = sample_inertia\n",
    "\n",
    "    names_list_sub_cluster[i] = [hru_names_list[x] for x in id_min_cluster]\n",
    "    print('min err in inertia:' , err_min )\n",
    "    np.save(data_path+'dist.in.cluster_'+str(i),dist[id_min_cluster])\n",
    "\n",
    "pickle.dump(names_list_sub_cluster, open(data_path+'names_list_sub_clusterwise.pkl', 'wb'))\n",
    "pickle.dump(names_list_cluster, open(data_path+'names_list_clusterwise.pkl', 'wb'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
